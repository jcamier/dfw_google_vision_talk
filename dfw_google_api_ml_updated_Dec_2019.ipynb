{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Welcome to the DFW Python Meetup - Dec 5, 2019\n",
    "\n",
    "# My talk today is focused on how we as Python Developers can use the various ML tools available to us to build more complex and insightful models.\n",
    "---------\n",
    "\n",
    "## Quick recap of what exactly is ML:\n",
    "## \"Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to effectively perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\"\n",
    "- https://en.wikipedia.org/wiki/Machine_learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To state this in another way, we are using math and statistics with a computer to make predictions about data\n",
    "<img src=\"ml.gif\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will be using the tools developed by Google. \n",
    "# Inspiration for this talk is based on a presentation that I saw at PyTexas 2019 -  Austin, TX\n",
    "<img src=\"pytexas_2019.png\" width=\"400\"/>\n",
    "<img src=\"google-cloud-platform-logo.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from google.cloud import pubsub_v1\n",
    "from google.cloud import translate_v2 as translate\n",
    "from google.cloud import storage\n",
    "from google.cloud import vision\n",
    "from google.cloud import language\n",
    "from google.cloud.vision import types as v_types\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "## Google Packages Pip Installs:\n",
    "# pip install google-cloud\n",
    "# pip install google-cloud-pubsub\n",
    "# pip install google-cloud-translate\n",
    "# pip install google-cloud-storage\n",
    "# pip install google-cloud-vision\n",
    "# pip install google-cloud-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python google cloud packages/versions as of presentation\n",
    "# google-cloud==0.34.0\n",
    "# google-cloud-core==1.0.3\n",
    "# google-cloud-language==1.3.0\n",
    "# google-cloud-pubsub==1.0.2\n",
    "# google-cloud-storage==1.22.0\n",
    "# google-cloud-translate==1.7.0\n",
    "# google-cloud-vision==0.39.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<h1 style=\"color:green;\">To use Google's ML API's, you will need a google cloud account and credentials.</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/products/ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "GOOGLE_CRED_FILE = \"image-to-sentiment-9462fc808e0f.json\"\n",
    "GOOGLE_CRED_FILE_PATH = os.path.join(CURRENT_DIR, GOOGLE_CRED_FILE)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_CRED_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate Necessary Google Vision and other Google Cloud Objects\n",
    "vision_client = vision.ImageAnnotatorClient()\n",
    "# translate_client = translate.Client()\n",
    "translate_client = translate.Client()\n",
    "publisher = pubsub_v1.PublisherClient()\n",
    "storage_client = storage.Client()\n",
    "language_client = language.LanguageServiceClient()\n",
    "\n",
    "with open('config.json') as f:\n",
    "    data = f.read()\n",
    "config = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with a basic image. I won't tell you nor Google what it is. Let's call it \"something\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_image = os.path.join(CURRENT_DIR, \"something.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the image file to annotate\n",
    "file_name = some_image\n",
    "\n",
    "# Load the image into memory\n",
    "with io.open(file_name, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = v_types.Image(content=content)\n",
    "\n",
    "# Performs label detection on the image file\n",
    "response = vision_client.label_detection(image=image)\n",
    "labels = response.label_annotations\n",
    "\n",
    "print('Labels:')\n",
    "for label in labels:\n",
    "    print(label.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Vision is telling us that the image is a cat. Well Let's see how it did?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<img src=\"something.jpg\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Job Google! Well let's try another picture..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_image2 = os.path.join(CURRENT_DIR, \"some_image_2.jpg\")\n",
    "\n",
    "file_name = some_image2\n",
    "\n",
    "with io.open(file_name, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "    image = v_types.Image(content=content)\n",
    "    \n",
    "response = vision_client.label_detection(image=image)\n",
    "labels = response.label_annotations\n",
    "\n",
    "print('Labels:')\n",
    "for label in labels:\n",
    "    print(label.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vision is telling us that the image is a dog. Well is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<img src=\"some_image_2.jpg\" width=\"600\" style=\"transform:rotate(90deg);\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yep, my pet dog called Duke.\n",
    "# Well Google was right again!\n",
    "# Noticed how I tried to trick the algorithm by introducing noise of other animals in the background but it was able to still determine the main image.\n",
    "# Hmm, how good is Google vision on reading images with text...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_image = os.path.join(CURRENT_DIR, \"text_image_1.jpg\")\n",
    "\n",
    "\n",
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            print(f'\\nBlock confidence: {block.confidence}\\n')\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                print(f'Paragraph confidence: {paragraph.confidence}')\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    print(f'Word text: {word_text} (confidence: {word.confidence}')\n",
    "\n",
    "                    for symbol in word.symbols:\n",
    "                        print(f'\\tSymbol: {symbol.text} (confidence: {symbol.confidence}')\n",
    "                        \n",
    "# Call function to detect document                        \n",
    "detect_document(text_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well I saw a lot of 99%'s, it seems Google Vision is pretty confident of it's abilities! Let's see this again but with just the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_document_text(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    print(f'Word text: {word_text}')\n",
    "                    \n",
    "detect_document_text(text_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can anyone guess what the image was?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<img src=\"text_image_1.jpg\" width=\"600\" style=\"transform:rotate(90deg);\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow, Google Vision got it right again!\n",
    "\n",
    "# Okay, Google is too smart for this simple ML stuff. Let's really try to trick it now!\n",
    "# Let's give it an image of some foreign language that is not commonly spoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_image_2 = os.path.join(CURRENT_DIR, \"IMG_0155.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<img src=\"IMG_0155.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "with io.open(text_image_2, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision.types.Image(content=content)\n",
    "\n",
    "response = client.document_text_detection(image=image)\n",
    "document = response.full_text_annotation\n",
    "\n",
    "for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    en_word = translate_client.translate(word_text, target_language=\"en\")\n",
    "                    en_word = en_word['translatedText']\n",
    "                    print('Word text: {} = {}'.format(\n",
    "                        word_text, en_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see this annotation of text in a more readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = []\n",
    "for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    en_word = translate_client.translate(word_text, target_language=\"en\")\n",
    "                    en_word = en_word['translatedText']\n",
    "                    list_of_words.append(en_word)\n",
    "translated_text = ' '.join(list_of_words)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay, so Google can translate a picture into text, then translate Icelandic into English! \n",
    "## Now that is cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.frettabladid.is/sport/liverpool-vann-i-fjorugum-grannaslag/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But wait, can Google tells us the sentiment of this article?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = types.Document(content=translated_text, type=enums.Document.Type.PLAIN_TEXT)\n",
    "annotations = language_client.analyze_sentiment(document=document)\n",
    "\n",
    "def print_result(annotations):\n",
    "    score = annotations.document_sentiment.score\n",
    "    magnitude = annotations.document_sentiment.magnitude\n",
    "\n",
    "    for index, sentence in enumerate(annotations.sentences):\n",
    "        sentence_sentiment = sentence.sentiment.score\n",
    "        print('Sentence {} has a sentiment score of {}'.format(\n",
    "            index, sentence_sentiment))\n",
    "\n",
    "    print('Overall Sentiment: score of {} with magnitude of {}'.format(\n",
    "        score, magnitude))\n",
    "    \n",
    "print_result(annotations=annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yes, Google Language can!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well maybe we are hundred years from now and find some ancient texts laying around. We take a picture on our future device and see what it can tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancient_text_image = os.path.join(CURRENT_DIR, \"ancient_text2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<img src=\"ancient_text2.jpg\" width=\"600\" style=\"transform:rotate(90deg);\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "with io.open(ancient_text_image, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision.types.Image(content=content)\n",
    "\n",
    "response = client.document_text_detection(image=image)\n",
    "document = response.full_text_annotation\n",
    "\n",
    "for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    en_word = translate_client.translate(word_text, target_language=\"en\")\n",
    "                    en_word = en_word['translatedText']\n",
    "                    print('Word text: {} = {} | Confidence: {}'.format(\n",
    "                        word_text, en_word, word.confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a more readable format..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = []\n",
    "for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    en_word = translate_client.translate(word_text, target_language=\"en\")\n",
    "                    en_word = en_word['translatedText']\n",
    "                    list_of_words.append(en_word)\n",
    "translated_text = ' '.join(list_of_words)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow, so Google ML could potentially help us with archaelogy research...?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay, well that is all cool and fine but my boss wants me to deliver business products with results. I mean like show me the numbers. How can Python &  Google ML help me?\n",
    "<img src=\"show_me_numbers.gif\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay, so we are asked right before lunch where is a good place to go to eat around here for some of our visitors. \n",
    "\n",
    "## A simple Google search won't do - we are data scientist, right?\n",
    "\n",
    "## 1) Let's scrape a website, 2) clean the html data, 3) convert it to a dataframe, 4) perform some ML sentiment analysis and then 5) display it as a histogram. We can then email this off to our boss and really impress him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_scrape = \"https://www.tripadvisor.com/Restaurant_Review-g56032-d2039635-Reviews-Our_Place_Indian_Cuisine-Irving_Texas.html#REVIEWS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r  = requests.get(url_to_scrape)\n",
    "\n",
    "data = r.text\n",
    "\n",
    "soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well here is our first view of the html data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well that is not usable, so let's try using a quick \"for loop\" to get something that is human readable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "counter = 0\n",
    "for review in soup.find_all('p'):\n",
    "    counter += 1\n",
    "    review_list.append(review.text)\n",
    "    print(counter, review.text)\n",
    "    \n",
    "review_text = ' '.join(review_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well, so we can scrape a website, but what does that really mean? Let's get something useful like the sentiment of these reviews? \n",
    "\n",
    "## Should we take our visiting guest there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sentiment_dict = {}\n",
    "def print_result(annotations):\n",
    "    score = annotations.document_sentiment.score\n",
    "    magnitude = annotations.document_sentiment.magnitude\n",
    "\n",
    "    for index, sentence in enumerate(annotations.sentences):\n",
    "        sentence_sentiment = sentence.sentiment.score\n",
    "        print('Sentence {} has a sentiment score of {}'.format(\n",
    "            index, sentence_sentiment))\n",
    "        reviews_sentiment_dict[index] = sentence_sentiment\n",
    "\n",
    "    print('Overall Sentiment: score of {} with magnitude of {}'.format(\n",
    "        score, magnitude))\n",
    "    \n",
    "document = types.Document(content=review_text, type=enums.Document.Type.PLAIN_TEXT)\n",
    "annotations = language_client.analyze_sentiment(document=document)\n",
    "print_result(annotations=annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well this can't really be a Data Science talk without having a dataframe and chart, can it? \n",
    "## What does this data mean really?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame.from_dict(reviews_sentiment_dict, orient='index', columns=['sentiment_score'])\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sentiment_df, kde=False, bins=5, rug=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well it looks like overall people like this restaurant, so I think we can recommend it.\n",
    "<img src=\"emoji_thumbs_up.jpg\" width=\"300\"/>\n",
    "\n",
    "--------\n",
    "# Hopefully you got inspired with some ideas with working with ML\n",
    "\n",
    "# Here is the github link of this talk:\n",
    "https://github.com/jcamier/dfw_google_vision_talk\n",
    "\n",
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
